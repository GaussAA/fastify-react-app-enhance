/**
 * AIé›†æˆæœåŠ¡
 * æ•´åˆæ‰€æœ‰AIåŠŸèƒ½æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„å¯¹è¯æ¥å£
 */

import { EventEmitter } from 'events';
import { PrismaClient } from '@prisma/client';
import { SessionManager, getSessionManager } from './session.service.js';
import { DialogueManager, getDialogueManager } from './dialogue.service.js';
import { AICoreService, getAICoreService } from './ai-core.service.js';
import { initializeLLMApi, getLLMApiClient } from '../lib/llm-api.js';

export interface ConversationRequest {
  sessionId: string;
  userId: string;
  message: string;
  options?: {
    model?: string;
    temperature?: number;
    maxTokens?: number;
    stream?: boolean;
    context?: Record<string, any>;
  };
}

export interface ConversationResponse {
  sessionId: string;
  messageId: string;
  response: string;
  intent: string;
  confidence: number;
  entities: Record<string, any>;
  qualityScore: number;
  processingTime: number;
  metadata: {
    model: string;
    tokens: number;
    context: Record<string, any>;
  };
}

export interface SystemHealth {
  status: 'healthy' | 'degraded' | 'unhealthy';
  services: {
    sessionManager: boolean;
    dialogueManager: boolean;
    aiCoreService: boolean;
    llmApi: boolean;
    database: boolean;
  };
  metrics: {
    activeSessions: number;
    averageResponseTime: number;
    errorRate: number;
    memoryUsage: number;
  };
  timestamp: Date;
}

export class AIIntegrationService extends EventEmitter {
  private sessionManager!: SessionManager;
  private dialogueManager!: DialogueManager;
  private aiCoreService!: AICoreService;
  private llmApiClient: any;
  private prisma: PrismaClient;
  private isInitialized: boolean = false;
  private healthCheckInterval: NodeJS.Timeout | null = null;
  private performanceMetrics: {
    totalRequests: number;
    successfulRequests: number;
    failedRequests: number;
    averageResponseTime: number;
    responseTimes: number[];
  };

  constructor(prisma: PrismaClient, fastify?: any) {
    super();
    this.prisma = prisma;
    this.performanceMetrics = {
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      averageResponseTime: 0,
      responseTimes: [],
    };

    this.initialize(fastify);
    this.startHealthMonitoring();
  }

  /**
   * åˆå§‹åŒ–æœåŠ¡
   */
  private async initialize(fastify?: any): Promise<void> {
    try {
      // åˆå§‹åŒ–å„ä¸ªæœåŠ¡
      this.sessionManager = getSessionManager(this.prisma, {
        maxIdleTime: 30 * 60 * 1000, // 30åˆ†é’Ÿ
        maxSessionDuration: 2 * 60 * 60 * 1000, // 2å°æ—¶
        maxMessageCount: 100,
        maxTokens: 100000,
        autoCleanup: true,
      });

      this.dialogueManager = getDialogueManager(this.sessionManager, {
        maxContextTurns: 10,
        stateTimeout: 5 * 60 * 1000, // 5åˆ†é’Ÿ
        enableInterruption: true,
        enableRecovery: true,
      });

      this.aiCoreService = getAICoreService(this.prisma);

      // åˆå§‹åŒ–LLM APIå®¢æˆ·ç«¯
      if (fastify) {
        const llmServiceManager = initializeLLMApi(fastify);
        await llmServiceManager.initializeDefaultService();
        this.llmApiClient = getLLMApiClient();
      }

      // è®¾ç½®äº‹ä»¶ç›‘å¬
      this.setupEventListeners();

      this.isInitialized = true;
      console.log('AI Integration Service initialized successfully');
    } catch (error) {
      console.error('Failed to initialize AI Integration Service:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†å¯¹è¯è¯·æ±‚
   */
  async processConversation(
    request: ConversationRequest
  ): Promise<ConversationResponse> {
    const startTime = Date.now();
    this.performanceMetrics.totalRequests++;

    try {
      if (!this.isInitialized) {
        throw new Error('Service not initialized');
      }

      // è·å–æˆ–åˆ›å»ºä¼šè¯
      let session = this.sessionManager.getSession(request.sessionId);
      if (!session) {
        session = await this.sessionManager.createSession(request.userId, {
          model: request.options?.model,
          temperature: request.options?.temperature,
          context: request.options?.context,
        });
      }

      // æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´
      await this.sessionManager.updateSession(request.sessionId, {
        metadata: {
          ...session.metadata,
          lastActivity: new Date(),
        },
      });

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
      await this.sessionManager.addMessage(request.sessionId, {
        role: 'user',
        content: request.message,
      });

      // æ„å›¾è¯†åˆ«
      const intentResult = await this.aiCoreService.recognizeIntent(
        request.message,
        session.context,
        request.sessionId
      );

      // å¤šè½®å¯¹è¯å¤„ç†
      const dialogueResult = await this.dialogueManager.processUserInput(
        request.sessionId,
        request.message
      );

      // çŸ¥è¯†åº“æŸ¥è¯¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
      let knowledgeResults = null;
      if (intentResult.intent === 'question' || intentResult.confidence < 0.7) {
        knowledgeResults = await this.aiCoreService.searchKnowledgeBase(
          request.message,
          { limit: 3, minRelevance: 0.5 }
        );
      }

      // ç”ŸæˆAIå“åº”
      const aiResponse = await this.generateAIResponse({
        userMessage: request.message,
        intent: intentResult,
        dialogueResult,
        knowledgeResults,
        session,
        options: request.options,
      });

      // æ·»åŠ AIå“åº”åˆ°ä¼šè¯
      await this.sessionManager.addMessage(request.sessionId, {
        role: 'assistant',
        content: aiResponse,
      });

      // è´¨é‡ç›‘æ§
      const qualityReport = await this.aiCoreService.monitorQuality(
        request.sessionId,
        `msg_${Date.now()}`,
        request.message,
        aiResponse,
        intentResult.alternatives.map(alternative => alternative.intent),
        [],
        { responseTime: Date.now() - startTime } as any // eslint-disable-line @typescript-eslint/no-explicit-any
      );

      const processingTime = Date.now() - startTime;
      this.updatePerformanceMetrics(processingTime, true);

      const response: ConversationResponse = {
        sessionId: request.sessionId,
        messageId: `msg_${Date.now()}`,
        response: aiResponse,
        intent: intentResult.intent,
        confidence: intentResult.confidence,
        entities: intentResult.entities,
        qualityScore: qualityReport.overallScore,
        processingTime,
        metadata: {
          model: session.metadata.model,
          tokens: 0, // å¯ä»¥ä»LLM APIå“åº”ä¸­è·å–
          context: session.context,
        },
      };

      this.emit('conversationProcessed', response);
      return response;
    } catch (error) {
      const processingTime = Date.now() - startTime;
      this.updatePerformanceMetrics(processingTime, false);

      console.error('Conversation processing error:', error);
      this.emit('conversationError', { request, error, processingTime });
      throw error;
    }
  }

  /**
   * ç”ŸæˆAIå“åº”
   */
  private async generateAIResponse(params: {
    userMessage: string;
    intent: any;
    dialogueResult: any;
    knowledgeResults: any;
    session: any;
    options?: any;
  }): Promise<string> {
    const {
      userMessage,
      intent,
      dialogueResult,
      knowledgeResults,
      session,
      options,
    } = params;

    // æ„å»ºä¸Šä¸‹æ–‡
    // const _context = this.buildContext(session, intent, knowledgeResults);

    // å‡†å¤‡LLMè¯·æ±‚
    const llmRequest = {
      messages: [
        ...session.conversationHistory.slice(-5), // æœ€è¿‘5æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
        {
          role: 'user',
          content: userMessage,
        },
      ],
      model: options?.model || session.metadata.model,
      temperature: options?.temperature || session.metadata.temperature,
      max_tokens: options?.maxTokens || 2000,
      stream: options?.stream || false,
    };

    try {
      // è°ƒç”¨LLM API
      const llmResponse = await this.llmApiClient.chat(llmRequest);

      if (llmResponse.choices && llmResponse.choices.length > 0) {
        let response = llmResponse.choices[0].message.content;

        // æ ¹æ®æ„å›¾å’ŒçŸ¥è¯†åº“ç»“æœä¼˜åŒ–å“åº”
        response = this.optimizeResponse(
          response,
          intent,
          knowledgeResults,
          dialogueResult
        );

        return response;
      } else {
        return dialogueResult.response || 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚';
      }
    } catch (error) {
      console.error('LLM API error:', error);
      // å›é€€åˆ°å¯¹è¯ç®¡ç†å™¨çš„å“åº”
      return (
        dialogueResult.response || 'æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚'
      );
    }
  }

  /**
   * æ„å»ºä¸Šä¸‹æ–‡
   */
  private buildContext(
    session: any,
    intent: any,
    knowledgeResults: any
  ): Record<string, any> {
    const context: Record<string, any> = {
      sessionId: session.id,
      userId: session.userId,
      currentState: session.context.currentState || 'greeting',
      intent: intent.intent,
      confidence: intent.confidence,
      entities: intent.entities,
      messageCount: session.metadata.messageCount,
      model: session.metadata.model,
    };

    if (knowledgeResults && knowledgeResults.results.length > 0) {
      context.knowledgeBase = {
        hasResults: true,
        resultCount: knowledgeResults.results.length,
        topResult: knowledgeResults.results[0],
      };
    }

    return context;
  }

  /**
   * ä¼˜åŒ–å“åº”
   */
  private optimizeResponse(
    response: string,
    intent: any,
    knowledgeResults: any,
    _dialogueResult: any
  ): string {
    let optimizedResponse = response;

    // å¦‚æœçŸ¥è¯†åº“æœ‰ç›¸å…³ç»“æœï¼Œå¯ä»¥å¢å¼ºå“åº”
    if (knowledgeResults && knowledgeResults.results.length > 0) {
      const topResult = knowledgeResults.results[0];
      if (topResult.relevanceScore > 0.8) {
        // é«˜ç›¸å…³æ€§ç»“æœï¼Œå¯ä»¥å¼•ç”¨çŸ¥è¯†åº“å†…å®¹
        optimizedResponse = this.enhanceWithKnowledge(
          optimizedResponse,
          topResult
        );
      }
    }

    // æ ¹æ®æ„å›¾è°ƒæ•´å“åº”é£æ ¼
    optimizedResponse = this.adjustResponseStyle(
      optimizedResponse,
      intent?.intent
    );

    return optimizedResponse;
  }

  /**
   * ç”¨çŸ¥è¯†åº“å†…å®¹å¢å¼ºå“åº”
   */
  private enhanceWithKnowledge(response: string, knowledgeEntry: any): string {
    // ç®€å•çš„å¢å¼ºç­–ç•¥ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
    if (response.length < 100 && knowledgeEntry.content.length > 50) {
      return `${response}\n\næ ¹æ®ç›¸å…³ä¿¡æ¯ï¼š${knowledgeEntry.content.substring(0, 200)}...`;
    }
    return response;
  }

  /**
   * è°ƒæ•´å“åº”é£æ ¼
   */
  private adjustResponseStyle(response: string, intent: string | undefined): string {
    if (!intent) {
      return response;
    }

    switch (intent) {
      case 'greeting':
        return response.replace(/^/, 'ğŸ˜Š ');
      case 'farewell':
        return response.replace(/^/, 'ğŸ‘‹ ');
      case 'thanks':
        return response.replace(/^/, 'ğŸ˜Š ');
      case 'complaint':
        return response.replace(/^/, 'ğŸ˜” ');
      default:
        return response;
    }
  }

  /**
   * è·å–ç³»ç»Ÿå¥åº·çŠ¶æ€
   */
  async getSystemHealth(): Promise<SystemHealth> {
    const health: SystemHealth = {
      status: 'healthy',
      services: {
        sessionManager: false,
        dialogueManager: false,
        aiCoreService: false,
        llmApi: false,
        database: false,
      },
      metrics: {
        activeSessions: 0,
        averageResponseTime: 0,
        errorRate: 0,
        memoryUsage: 0,
      },
      timestamp: new Date(),
    };

    try {
      // æ£€æŸ¥ä¼šè¯ç®¡ç†å™¨
      if (this.sessionManager) {
        const stats = this.sessionManager.getSessionStats();
        health.services.sessionManager = true;
        health.metrics.activeSessions = stats.activeSessions;
      }

      // æ£€æŸ¥å¯¹è¯ç®¡ç†å™¨
      if (this.dialogueManager) {
        // const stats = this.dialogueManager.getDialogueStats();
        health.services.dialogueManager = true;
      }

      // æ£€æŸ¥AIæ ¸å¿ƒæœåŠ¡
      if (this.aiCoreService) {
        health.services.aiCoreService = true;
      }

      // æ£€æŸ¥LLM API
      try {
        if (this.llmApiClient) {
          await this.llmApiClient.healthCheck();
          health.services.llmApi = true;
        } else {
          health.services.llmApi = false;
        }
      } catch {
        health.services.llmApi = false;
      }

      // æ£€æŸ¥æ•°æ®åº“
      try {
        await this.prisma.$queryRaw`SELECT 1`;
        health.services.database = true;
      } catch {
        health.services.database = false;
      }

      // è®¡ç®—æ€§èƒ½æŒ‡æ ‡
      health.metrics.averageResponseTime =
        this.performanceMetrics.averageResponseTime;
      health.metrics.errorRate =
        this.performanceMetrics.totalRequests > 0
          ? this.performanceMetrics.failedRequests /
          this.performanceMetrics.totalRequests
          : 0;

      // è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
      const memUsage = process.memoryUsage();
      health.metrics.memoryUsage = memUsage.heapUsed / memUsage.heapTotal;

      // ç¡®å®šæ•´ä½“çŠ¶æ€
      const serviceCount = Object.values(health.services).filter(
        Boolean
      ).length;
      const totalServices = Object.keys(health.services).length;

      if (serviceCount === totalServices) {
        health.status = 'healthy';
      } else if (serviceCount >= totalServices * 0.7) {
        health.status = 'degraded';
      } else {
        health.status = 'unhealthy';
      }
    } catch (error) {
      console.error('Health check error:', error);
      health.status = 'unhealthy';
    }

    return health;
  }

  /**
   * è®¾ç½®äº‹ä»¶ç›‘å¬
   */
  private setupEventListeners(): void {
    // ä¼šè¯ç®¡ç†å™¨äº‹ä»¶
    this.sessionManager.on('sessionCreated', session => {
      this.emit('sessionCreated', session);
    });

    this.sessionManager.on('sessionExpired', session => {
      this.emit('sessionExpired', session);
    });

    // å¯¹è¯ç®¡ç†å™¨äº‹ä»¶
    this.dialogueManager.on('dialogueStateUpdated', dialogue => {
      this.emit('dialogueStateUpdated', dialogue);
    });

    // AIæ ¸å¿ƒæœåŠ¡äº‹ä»¶
    this.aiCoreService.on('qualityReported', report => {
      this.emit('qualityReported', report);
    });
  }

  /**
   * å¯åŠ¨å¥åº·ç›‘æ§
   */
  private startHealthMonitoring(): void {
    this.healthCheckInterval = setInterval(async () => {
      try {
        const health = await this.getSystemHealth();
        this.emit('healthChecked', health);

        // å¦‚æœç³»ç»Ÿä¸å¥åº·ï¼Œè§¦å‘å‘Šè­¦
        if (health.status === 'unhealthy') {
          this.emit('systemUnhealthy', health);
        }
      } catch (error) {
        console.error('Health monitoring error:', error);
      }
    }, 60000); // æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  }

  /**
   * æ›´æ–°æ€§èƒ½æŒ‡æ ‡
   */
  private updatePerformanceMetrics(
    responseTime: number,
    success: boolean
  ): void {
    this.performanceMetrics.responseTimes.push(responseTime);

    // ä¿æŒæœ€è¿‘1000ä¸ªå“åº”æ—¶é—´
    if (this.performanceMetrics.responseTimes.length > 1000) {
      this.performanceMetrics.responseTimes =
        this.performanceMetrics.responseTimes.slice(-1000);
    }

    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    this.performanceMetrics.averageResponseTime =
      this.performanceMetrics.responseTimes.reduce((a, b) => a + b, 0) /
      this.performanceMetrics.responseTimes.length;

    if (success) {
      this.performanceMetrics.successfulRequests++;
    } else {
      this.performanceMetrics.failedRequests++;
    }
  }

  /**
   * è·å–æ€§èƒ½ç»Ÿè®¡
   */
  getPerformanceStats(): {
    totalRequests: number;
    successfulRequests: number;
    failedRequests: number;
    successRate: number;
    averageResponseTime: number;
    errorRate: number;
  } {
    const total = this.performanceMetrics.totalRequests;
    const successful = this.performanceMetrics.successfulRequests;
    const failed = this.performanceMetrics.failedRequests;

    return {
      totalRequests: total,
      successfulRequests: successful,
      failedRequests: failed,
      successRate: total > 0 ? successful / total : 0,
      averageResponseTime: this.performanceMetrics.averageResponseTime,
      errorRate: total > 0 ? failed / total : 0,
    };
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    if (this.healthCheckInterval) {
      clearInterval(this.healthCheckInterval);
    }

    if (this.sessionManager) {
      await this.sessionManager.cleanup();
    }

    console.log('AI Integration Service cleaned up');
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
let aiIntegrationServiceInstance: AIIntegrationService | null = null;

export function getAIIntegrationService(
  prisma?: PrismaClient,
  fastify?: any
): AIIntegrationService {
  if (!aiIntegrationServiceInstance && prisma) {
    aiIntegrationServiceInstance = new AIIntegrationService(prisma, fastify);
  }
  return aiIntegrationServiceInstance!;
}
